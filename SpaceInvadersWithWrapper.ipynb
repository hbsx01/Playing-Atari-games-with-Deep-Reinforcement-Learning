{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2Gxvnq5pC7g","executionInfo":{"status":"ok","timestamp":1701752655075,"user_tz":-480,"elapsed":29087,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"outputId":"6f5b12bb-d414-4886-a498-2649ccad7036"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Install Dependencies"],"metadata":{"id":"vu3-5Tn-prhY"}},{"cell_type":"code","source":["%%capture\n","!apt install python-opengl\n","!apt install ffmpeg\n","# !apt install xvfb\n","!pip install einops\n","!pip install pyvirtualdisplay\n","!sudo apt-get install xvfb\n","!pip install pyglet==1.5.1 gymnasium[atari]\n","!pip install ale-py\n","!pip install gymnasium[accept-rom-license]\n","!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt"],"metadata":{"id":"dUTi-ZKYps80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Virtual display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0\n","                          , size=(1400, 900))\n","virtual_display.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBfwmylvpvTt","executionInfo":{"status":"ok","timestamp":1701752730772,"user_tz":-480,"elapsed":653,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"outputId":"aa1a3fd6-ba6d-4dba-f609-cff6ae08a9ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x78dfc37819f0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import numpy as np\n","import warnings\n","from collections import namedtuple\n","import random\n","from itertools import count\n","warnings.filterwarnings(\"ignore\")\n","\n","from collections import deque\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from einops.layers.torch import Rearrange, Reduce\n","from torch.distributions import Categorical\n","from torchvision.transforms.v2 import Resize, Grayscale\n","\n","# Gymnasium\n","import gymnasium as gym\n","import gym_pygame\n","\n","# Hugging Face Hub\n","from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n","import imageio\n","\n","import os\n","import pyvirtualdisplay\n","from datetime import datetime\n","import base64\n","import io\n","from IPython import display as ipythondisplay"],"metadata":{"id":"wdqb2QXUpwam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"basic wrappers, useful for reinforcement learning on gym envs\"\"\"\n","# Mostly copy-pasted from https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py\n","import cv2\n","from gym import spaces\n","import gym\n","from collections import deque\n","import os\n","os.environ.setdefault('PATH', '')\n","cv2.ocl.setUseOpenCL(False)"],"metadata":{"id":"cZJtsAOfxB4g","executionInfo":{"status":"ok","timestamp":1701752739162,"user_tz":-480,"elapsed":6,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2dee8937-c153-4b29-8cd2-fd3f1fdf235e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YDZ8C2lpxeu","executionInfo":{"status":"ok","timestamp":1701752739162,"user_tz":-480,"elapsed":5,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"outputId":"fc70be8e-98aa-4651-f6f6-6f421c73b261"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["# DQN Algorithm with Wrapper"],"metadata":{"id":"WXqfxM2Ppza5"}},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"mVpXJ6cgp2F_"}},{"cell_type":"code","source":["re_shape = 96\n","embd = 128\n","p_shape = 8\n","num_p = (re_shape//p_shape)**2\n","fac = 3\n","num_layer = 2\n","frame_to_stack = 4"],"metadata":{"id":"zYIjd6a1vYsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def nrs(x, dim = -1):\n","  return vec_norm(x.relu(), dim = dim)**2\n","\n","def vec_norm(x, dim = -1, epsilon = 1e-10):\n","  return torch.div(x, torch.linalg.vector_norm(x, dim = dim, keepdim = True) + epsilon)\n","\n","class att(nn.Module):\n","  def __init__(self, head = 24):\n","    super().__init__()\n","    self.expand = nn.Sequential(nn.LayerNorm(embd), nn.Linear(embd, int(head) * 3, bias = False))\n","    self.scale = torch.sqrt(torch.tensor(head, dtype = torch.float32))\n","    self.proj = nn.Linear(int(head), fac * embd)\n","\n","  def forward(self, x):\n","    q, k, v = F.gelu(self.expand(x)).chunk(3, -1)\n","    return F.gelu(self.proj(torch.einsum('...nm,...mf->...nf', nrs(torch.einsum('...nc,...mc->...nm', q, k)/self.scale, dim = -1), v)))\n","\n","class spatial_proj(nn.Module):\n","  def __init__(self, p = num_p, c = num_p):\n","    super(spatial_proj, self).__init__()\n","    self.proj = nn.Conv1d(p, p, 1, groups = p//c)\n","    nn.init.constant_(self.proj.weight,0)\n","    nn.init.constant_(self.proj.bias,1)\n","\n","  def forward(self, x):\n","    return self.proj(x)\n","\n","class gMLP(nn.Module):\n","  def __init__(self, ):\n","    super().__init__()\n","    self.norm = nn.LayerNorm(embd*fac)\n","    self.expand = nn.Sequential(nn.LayerNorm(embd), nn.Linear(embd, embd*fac*2, bias = False))\n","    self.proj = spatial_proj()\n","    self.proj1 = spatial_proj(c = 2)\n","    self.cp = nn.Linear(embd*fac, embd)\n","    self.res = att()\n","\n","  def forward(self, x):\n","    u, v = F.gelu(self.expand(x)).chunk(2, -1)\n","    v = self.norm(v)\n","    return F.gelu(self.cp(u * (self.proj(v) + self.proj1(v) + self.res(x)))) + x\n","\n","class nnModel(nn.Module):\n","  def __init__(self, env, num_layer = num_layer):\n","    super().__init__()\n","    self.patch = nn.Sequential(nn.BatchNorm2d(frame_to_stack), nn.Conv2d(frame_to_stack, embd, p_shape, p_shape), Rearrange('b n h w-> b (h w) n'))\n","    self.model = nn.Sequential(*[gMLP() for _ in range(num_layer)])\n","    self.proj = nn.Sequential(nn.Linear(embd*num_p, embd), nn.Linear(embd, env.action_space.n))\n","\n","  def forward(self, x):\n","    #return self.proj(F.relu(self.model(self.patch(x)).mean(dim = 1)))\n","    return self.proj(F.relu(nn.Flatten()(self.model(self.patch(x)))))\n","\n","def prepro(x):\n","  return Resize((re_shape, re_shape))(Grayscale()(Rearrange('b s h w c -> b s c h w')(x)))\n","\n","class ReplayMemory(object):\n","\n","    def __init__(self, capacity):\n","        self.memory = deque([], maxlen=capacity)\n","\n","    def push(self, *args):\n","        self.memory.append(Transition(*args))\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","\n","class DQN(nn.Module):\n","  def __init__(self, env):\n","    super(DQN, self).__init__()\n","    self.layer = nnModel(env)\n","    nn.Sequential(# scale along color channel\n","    #nn.LayerNorm(3),\n","# shape -> (b, c, h, w) to fit pytorch cnn\n","\n","    #Rearrange('b h w c -> b c h w'),\n","    nn.BatchNorm2d(frame_to_stack),\n","# conv on h, w\n","    nn.Conv2d(frame_to_stack, 32, 8, 4,),\n","# reduce h, w by half\n","    #nn.MaxPool2d((2,2)),\n","# activate\n","    nn.GELU(),\n","# conv on h, w\n","    nn.Conv2d(32, 64, 4, 2,),\n","# reduce h, w by half\n","    nn.MaxPool2d((2,2)),\n","# activate\n","    nn.GELU(),\n","# conv on h, w\n","    nn.Conv2d(64, 64, 3, 1,),\n","# reduce h, w by half\n","    nn.MaxPool2d((2,2)),\n","# activate\n","    nn.GELU(),\n","# compress the h, w, c into 1D vector\n","    nn.Flatten(),\n","# vanilla mlp and project to action space\n","    nn.Linear(64, 32),\n","    nn.ReLU(),\n","    nn.Linear(32, env.action_space.n),\n","    )\n","\n","  def forward(self, x):\n","# Input shape (b, 210, 160, 3)\n","# shape: (batch, height, width, channel)\n","    return self.layer(x)\n","\n","class NoopResetEnv(gym.Wrapper):\n","    def __init__(self, env, noop_max=30):\n","        \"\"\"Sample initial states by taking random number of no-ops on reset.\n","        No-op is assumed to be action 0.\n","        \"\"\"\n","        gym.Wrapper.__init__(self, env)\n","        self.noop_max = noop_max\n","        self.override_num_noops = None\n","        self.noop_action = 0\n","        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n","\n","    def reset(self, **kwargs):\n","        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n","        self.env.reset(**kwargs)\n","        if self.override_num_noops is not None:\n","            noops = self.override_num_noops\n","        else:\n","            noops = self.unwrapped.np_random.integers(1, self.noop_max + 1)  # pylint: disable=E1101\n","        assert noops > 0\n","        obs = None\n","        for _ in range(noops):\n","            obs, _, done, _ = self.env.step(self.noop_action)\n","            if done:\n","                obs = self.env.reset(**kwargs)\n","        return obs\n","\n","    def step(self, ac):\n","        return self.env.step(ac)\n","\n","\n","class FireResetEnv(gym.Wrapper):\n","    def __init__(self, env):\n","        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n","        gym.Wrapper.__init__(self, env)\n","        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n","        assert len(env.unwrapped.get_action_meanings()) >= 3\n","\n","    def reset(self, **kwargs):\n","        self.env.reset(**kwargs)\n","        obs, _, done, _ = self.env.step(1)\n","        if done:\n","            self.env.reset(**kwargs)\n","        obs, _, done, _ = self.env.step(2)\n","        if done:\n","            self.env.reset(**kwargs)\n","        return obs\n","\n","    def step(self, ac):\n","        return self.env.step(ac)\n","\n","\n","class EpisodicLifeEnv(gym.Wrapper):\n","    def __init__(self, env):\n","        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n","        Done by DeepMind for the DQN and co. since it helps value estimation.\n","        \"\"\"\n","        gym.Wrapper.__init__(self, env)\n","        self.lives = 0\n","        self.was_real_done = True\n","\n","    def step(self, action):\n","        obs, reward, done, info = self.env.step(action)\n","        self.was_real_done = done\n","        # check current lives, make loss of life terminal,\n","        # then update lives to handle bonus lives\n","        lives = self.env.unwrapped.ale.lives()\n","        if lives < self.lives and lives > 0:\n","            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n","            # so it's important to keep lives > 0, so that we only reset once\n","            # the environment advertises done.\n","            done = True\n","        self.lives = lives\n","        return obs, reward, done, info\n","\n","    def reset(self, **kwargs):\n","        \"\"\"Reset only when lives are exhausted.\n","        This way all states are still reachable even though lives are episodic,\n","        and the learner need not know about any of this behind-the-scenes.\n","        \"\"\"\n","        if self.was_real_done:\n","            obs = self.env.reset(**kwargs)\n","        else:\n","            # no-op step to advance from terminal/lost life state\n","            obs, _, _, _ = self.env.step(0)\n","        self.lives = self.env.unwrapped.ale.lives()\n","        return obs\n","\n","\n","class MaxAndSkipEnv(gym.Wrapper):\n","    def __init__(self, env, skip=4):\n","        \"\"\"Return only every `skip`-th frame\"\"\"\n","        gym.Wrapper.__init__(self, env)\n","        # most recent raw observations (for max pooling across time steps)\n","        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n","        self._skip = skip\n","\n","    def step(self, action):\n","        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n","        total_reward = 0.0\n","        done = None\n","        for i in range(self._skip):\n","            obs, reward, done, info = self.env.step(action)\n","            if i == self._skip - 2:\n","                self._obs_buffer[0] = obs\n","            if i == self._skip - 1:\n","                self._obs_buffer[1] = obs\n","            total_reward += reward\n","            if done:\n","                break\n","        # Note that the observation on the done=True frame\n","        # doesn't matter\n","        max_frame = self._obs_buffer.max(axis=0)\n","\n","        return max_frame, total_reward, done, info\n","\n","    def reset(self, **kwargs):\n","        return self.env.reset(**kwargs)\n","\n","\n","class ClipRewardEnv(gym.RewardWrapper):\n","    def __init__(self, env):\n","        gym.RewardWrapper.__init__(self, env)\n","\n","    def reward(self, reward):\n","        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n","        return np.sign(reward)\n","\n","\n","class WarpFrame(gym.ObservationWrapper):\n","    def __init__(self, env, width=84, height=84, grayscale=True):\n","        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n","        gym.ObservationWrapper.__init__(self, env)\n","        self.width = width\n","        self.height = height\n","        self.grayscale = grayscale\n","        if self.grayscale:\n","            self.observation_space = spaces.Box(low=0, high=255,\n","                                                shape=(self.height, self.width, 1), dtype=np.uint8)\n","        else:\n","            self.observation_space = spaces.Box(low=0, high=255,\n","                                                shape=(self.height, self.width, 3), dtype=np.uint8)\n","\n","    def observation(self, frame):\n","        if self.grayscale:\n","            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n","        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n","        if self.grayscale:\n","            frame = np.expand_dims(frame, -1)\n","        return frame\n","\n","\n","class LazyFrames(object):\n","    r\"\"\"Ensures common frames are only stored once to optimize memory use.\n","    To further reduce the memory use, it is optionally to turn on lz4 to\n","    compress the observations.\n","    .. note::\n","        This object should only be converted to numpy array just before forward pass.\n","    \"\"\"\n","\n","    def __init__(self, frames, lz4_compress=False):\n","        if lz4_compress:\n","            from lz4.block import compress\n","            self.shape = frames[0].shape\n","            self.dtype = frames[0].dtype\n","            frames = [compress(frame) for frame in frames]\n","        self._frames = frames\n","        self.lz4_compress = lz4_compress\n","\n","    def __array__(self, dtype=None):\n","        if self.lz4_compress:\n","            from lz4.block import decompress\n","            frames = [np.frombuffer(decompress(frame), dtype=self.dtype).reshape(self.shape) for frame in self._frames]\n","        else:\n","            frames = self._frames\n","        out = np.stack(frames, axis=0)\n","        if dtype is not None:\n","            out = out.astype(dtype)\n","        return out\n","\n","    def __len__(self):\n","        return len(self.__array__())\n","\n","    def __getitem__(self, i):\n","        return self.__array__()[i]\n","\n","\n","class FrameStack(gym.Wrapper):\n","    def __init__(self, env, k):\n","        \"\"\"Stack k last frames.\n","        Returns lazy array, which is much more memory efficient.\n","        See Also\n","        --------\n","        baselines.common.atari_wrappers.LazyFrames\n","        \"\"\"\n","        gym.Wrapper.__init__(self, env)\n","        self.k = k\n","        self.frames = deque([], maxlen=k)\n","        shp = env.observation_space.shape\n","        self.observation_space = spaces.Box(low=0, high=255, shape=(\n","            shp[:-1] + (shp[-1] * k,)), dtype=env.observation_space.dtype)\n","\n","    def reset(self):\n","        ob = self.env.reset()\n","        for _ in range(self.k):\n","            self.frames.append(ob)\n","        return self._get_ob()\n","\n","    def step(self, action):\n","        ob, reward, done, info = self.env.step(action)\n","        self.frames.append(ob)\n","        return self._get_ob(), reward, done, info\n","\n","    def _get_ob(self):\n","        assert len(self.frames) == self.k\n","        return LazyFrames(list(self.frames))\n","\n","\n","def wrapper(env, terminal_on_life_loss=True, noop_max=20, frame_skip=2,\n","            num_stack=frame_to_stack, screen_size=(re_shape, re_shape), grayscale=True, clip_reward=False):\n","    \"\"\"Apply a common set of wrappers for Atari games.\"\"\"\n","    if terminal_on_life_loss:\n","        env = EpisodicLifeEnv(env)\n","    if noop_max:\n","        env = NoopResetEnv(env, noop_max=10)\n","    if frame_skip:\n","        env = MaxAndSkipEnv(env, skip=frame_skip)\n","    try:\n","        if 'FIRE' in env.unwrapped.get_action_meanings():\n","            env = FireResetEnv(env)\n","    except Exception:\n","        pass\n","    if screen_size or grayscale:\n","        env = WarpFrame(env, *(screen_size + (grayscale,)))\n","    if num_stack:\n","        env = FrameStack(env, num_stack)\n","    if clip_reward:\n","        env = ClipRewardEnv(env)\n","    return env\n","\n","if not os.environ.get('DISPLAY'):\n","    pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n","\n","def embed_video(video_path, width=640):\n","    content = io.open(video_path, 'rb').read()\n","    b64 = base64.b64encode(content)\n","    video_tag = '''\n","\n","    '''.format(b64.decode(), width)\n","    ipythondisplay.display(ipythondisplay.HTML(video_tag))\n","\n","class VideoRecorder:\n","    def __init__(self, filename, fps=30):\n","        self.filename = filename\n","        self.writer = imageio.get_writer(filename, fps=fps)\n","\n","    def record_frame(self, env):\n","        frame = env.render()\n","        self.writer.append_data(frame)\n","\n","    def close(self, *args, **kwargs):\n","        self.writer.close(*args, **kwargs)\n","\n","    def play(self):\n","        self.close()\n","        embed_video(self.filename)\n","\n","    def __enter__(self):\n","        return self\n","\n","    def __exit__(self, type, value, traceback):\n","        self.play()\n","\n","def select_action(state, test = False):\n","  global moving_eps\n","  sample = random.random()\n","  if test:\n","    eps = 0\n","  else:\n","    eps = moving_eps\n","    if moving_eps > hyperparameters[\"end_epsilon\"]: moving_eps = moving_eps * hyperparameters[\"eps_decay\"]\n","  if sample > eps:\n","    with torch.no_grad():\n","#argmax expected return in actions\n","      return policy_net(state).max(1).indices.view(1, 1)\n","#random action\n","  else:\n","    return torch.tensor([[env.action_space.sample()]], device = device, dtype=torch.long)\n","\n","def optimize():\n","    if len(memory) < batch_size:\n","        return\n","    transitions = memory.sample(batch_size)\n","    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation). This converts batch-array of Transitions\n","    # to Transition of batch-arrays.\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    # (a final state would've been the one after which simulation ended)\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.bool)\n","    non_final_next_states = torch.cat([torch.tensor(s, dtype = torch.float32, device = device) for s in batch.next_state\n","                                               if s is not None])\n","    #state_batch = torch.cat(tuple(torch.tensor(batch.state, dtype = torch.float32, device = device)))\n","    #action_batch = torch.cat(tuple(torch.tensor(batch.action, dtype = torch.float32, device = device)))\n","    #reward_batch = torch.cat(tuple(torch.tensor(batch.reward, dtype = torch.float32, device = device)))\n","    state_batch = torch.tensor(batch.state, dtype = torch.float32, device = device).squeeze(-1)\n","    action_batch = torch.tensor(batch.action, dtype = torch.int64, device = device).squeeze()\n","    reward_batch = torch.tensor(batch.reward, dtype = torch.float32, device = device).squeeze(-1)\n","    #print(state_batch.shape)\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken. These are the actions which would've been taken\n","    # for each batch state according to policy_net\n","    state_action_values = policy_net(state_batch).gather(1, action_batch.reshape(-1,1))\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    # Expected values of actions for non_final_next_states are computed based\n","    # on the \"older\" target_net; selecting their best reward with max(1).values\n","    # This is merged based on the mask, such that we'll have either the expected\n","    # state value or 0 in case the state was final.\n","    next_state_values = torch.zeros(batch_size, device=device)\n","    #print(non_final_next_states.shape)\n","    with torch.no_grad():\n","        next_state_values[non_final_mask] = target_net(non_final_next_states.squeeze(-1).reshape(-1, frame_to_stack, re_shape, re_shape)).max(1).values\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * hyperparameters[\"gamma\"]) + reward_batch\n","\n","    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    # In-place gradient clipping\n","    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 10)\n","    optimizer.step()\n","    global global_step\n","    global_step += 1\n","\n","def Re(x):\n","  return Rearrange('b h w c -> b c h w')(x)"],"metadata":{"id":"3Nwxh2y5p3b_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initializer"],"metadata":{"id":"YAAqHZ6jp4O8"}},{"cell_type":"code","source":["Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","# Other Environment\n","# Seaquest-v4\n","# Pong-v4\n","# Breakout-v4\n","# Qbert-v4\n","# Enduro-v4\n","# BeamRider-v4\n","# SpaceInvaders-v4\n","\n","# Create the env\n","env_id = 'Seaquest-v4'\n","env = gym.make(gym.spec(env_id), render_mode='rgb_array')\n","env = wrapper(env)\n","env.reset()\n","\n","# Create the evaluation env\n","eval_env = gym.make(env_id)\n","\n","# Get the state space and action space\n","s_size = env.observation_space.shape[0]\n","a_size = env.action_space.n\n","\n","print(s_size)\n","print(a_size)\n","\n","hyperparameters = {\n","    \"h_size\": 16,\n","    \"n_training_episodes\": 1000000,\n","    \"n_evaluation_episodes\": 1000,\n","    \"max_t\": 1000,\n","    \"gamma\": 0.95,\n","    \"start_epsilon\": 0.2,\n","    \"end_epsilon\":0.05,\n","    \"eps_decay\": 1e-4,\n","    \"lr\": 5e-3,\n","    \"update_interval\":50,\n","    \"env_id\": env_id,\n","    \"state_space\": s_size,\n","    \"action_space\": a_size,\n","  }\n","\n","criterion = nn.MSELoss()\n","batch_size = 32\n","num_episodes = 2\n","#stepsize = 1e-1\n","\n","policy_net = DQN(env).to(device)\n","target_net = DQN(env).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","\n","optimizer = optim.RAdam(policy_net.parameters(), lr = hyperparameters[\"lr\"], weight_decay = 1e-3)\n","memory = ReplayMemory(100000)\n","\n","moving_eps = hyperparameters[\"start_epsilon\"]\n","global_step = 0\n","\n","print(\"_____OBSERVATION SPACE_____ \\n\")\n","print(\"The State Space is: \", s_size)\n","#print(\"Sample observation\", env.observation_space.sample()) # Get a random observation\n","print(\"\\n _____ACTION SPACE_____ \\n\")\n","print(\"The Action Space is: \", a_size)\n","print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtSDE23Cp033","executionInfo":{"status":"ok","timestamp":1701753757212,"user_tz":-480,"elapsed":669,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"outputId":"99ea44ac-58a7-43d0-c8a8-d9968a6d5927"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["96\n","18\n","_____OBSERVATION SPACE_____ \n","\n","The State Space is:  96\n","\n"," _____ACTION SPACE_____ \n","\n","The Action Space is:  18\n","Action Space Sample 7\n"]}]},{"cell_type":"markdown","source":["## Testing"],"metadata":{"id":"Z8KaPOH4u4eR"}},{"cell_type":"code","source":["# Run the test\n","counter = 0\n","\n","for i_episode in range(10):\n","    print(counter, end=' ')\n","    counter += 1\n","    # reset the env every episode\n","    state = env.reset()\n","    for t in count():\n","        action = select_action(torch.tensor(state, dtype = torch.float32, device = device).squeeze(-1).unsqueeze(0))\n","        observation, reward, done, _ = env.step(action.item())\n","        reward = torch.tensor([reward], device=device)\n","\n","        if done:\n","          next_state = None #LazyFrames(torch.zeros((1,frame_to_stack,reshape,reshape)))\n","        else:\n","          next_state = observation\n","\n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","\n","        # Move to the next state\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the policy network)\n","        optimize()\n","\n","        if (global_step + 1 + hyperparameters[\"update_interval\"])%hyperparameters[\"update_interval\"] == 0:\n","          target_net.load_state_dict(policy_net.state_dict())\n","        if done:\n","            break\n","\n","def random_filename_experiment_design(iter, game, experiment_design):\n","    return f'/content/drive/MyDrive/SDSC4001_Project/VideoRecording/SeaQuestWrapper/ExperimentDesign{game}{experiment_design}_{iter}_Wrapper_CNN.mp4'\n","\n","rwd_list = []\n","game = env_id\n","experiment_no = 2 # PLEASE CHANGE, IF NO CHANGE VIDEO GONE\n","print('Complete')\n","# Test them to 10 video recording real-time game experience\n","for i in range(10):\n","    rwd = 0\n","    with VideoRecorder(random_filename_experiment_design(i, game, experiment_no)) as rec:\n","        state = env.reset()\n","        while True:\n","            rec.record_frame(env)\n","            action = select_action(torch.tensor(state, dtype = torch.float32, device = device).squeeze(-1).unsqueeze(0))\n","            #obs, reward, terminated, truncated , info = env.step(action)\n","            obs, reward, done , info = env.step(action)\n","\n","            state = obs#torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n","            rwd += reward\n","            #done = terminated or truncated\n","            if done:\n","                break\n","    print(rwd)\n","    rwd_list.append(rwd)\n","print(rwd_list, np.mean(rwd_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"e5_XChKJH34p","executionInfo":{"status":"ok","timestamp":1701757334945,"user_tz":-480,"elapsed":3558815,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"outputId":"781f74d2-e36d-4808-a619-6f005e36b660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 1 2 3 4 5 6 7 8 9 Complete\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.0\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n"]}]},{"cell_type":"code","source":["# Run the test\n","counter = 0\n","\n","for i_episode in range(10):\n","    print(counter, end=' ')\n","    counter += 1\n","    # reset the env every episode\n","    state = env.reset()\n","    for t in count():\n","        action = select_action(torch.tensor(state, dtype = torch.float32, device = device).squeeze(-1).unsqueeze(0))\n","        observation, reward, done, _ = env.step(action.item())\n","        reward = torch.tensor([reward], device=device)\n","\n","        if done:\n","          next_state = None #LazyFrames(torch.zeros((1,frame_to_stack,reshape,reshape)))\n","        else:\n","          next_state = observation\n","\n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","\n","        # Move to the next state\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the policy network)\n","        optimize()\n","\n","        if (global_step + 1 + hyperparameters[\"update_interval\"])%hyperparameters[\"update_interval\"] == 0:\n","          target_net.load_state_dict(policy_net.state_dict())\n","        if done:\n","            break\n","\n","def random_filename_experiment_design(iter, game, experiment_design):\n","    return f'/content/drive/MyDrive/SDSC4001_Project/VideoRecording/SpaceInvadersWrapper/ExperimentDesign{game}{experiment_design}_{iter}_Wrapper_CNN.mp4'\n","\n","rwd_list = []\n","game = env_id\n","experiment_no = 3 # PLEASE CHANGE, IF NO CHANGE VIDEO GONE\n","print('Complete')\n","# Test them to 10 video recording real-time game experience\n","for i in range(10):\n","    rwd = 0\n","    with VideoRecorder(random_filename_experiment_design(i, game, experiment_no)) as rec:\n","        state = env.reset()\n","        while True:\n","            rec.record_frame(env)\n","            action = select_action(torch.tensor(state, dtype = torch.float32, device = device).squeeze(-1).unsqueeze(0))\n","            #obs, reward, terminated, truncated , info = env.step(action)\n","            obs, reward, done , info = env.step(action)\n","\n","            state = obs#torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n","            rwd += reward\n","            #done = terminated or truncated\n","            if done:\n","                break\n","    print(rwd)\n","    rwd_list.append(rwd)\n","print(rwd_list, np.mean(rwd_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"0oVFDo5-qcLG","outputId":"91880e9d-4835-43bb-e895-4d3d39e9b631"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 1 2 3 4 "]},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["Complete\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["145.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["45.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["30.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["230.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["70.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["30.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["40.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["25.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["30.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["def random_filename_experiment_design(iter, game, experiment_design):\n","    return f'/content/drive/MyDrive/SDSC4001_Project/VideoRecording/SpaceInvadersWrapper/ExperimentDesign{game}{experiment_design}_{iter}_Wrapper.mp4'\n","\n","rwd_list = []\n","game = env_id\n","experiment_no = 4 # PLEASE CHANGE, IF NO CHANGE VIDEO GONE\n","print('Complete')\n","# Test them to 10 video recording real-time game experience\n","for i in range(10):\n","    rwd = 0\n","    with VideoRecorder(random_filename_experiment_design(i, game, experiment_no)) as rec:\n","        state = env.reset()\n","        while True:\n","            rec.record_frame(env)\n","            action = select_action(torch.tensor(state, dtype = torch.float32, device = device).squeeze(-1).unsqueeze(0))\n","            #obs, reward, terminated, truncated , info = env.step(action)\n","            obs, reward, done , info = env.step(action)\n","\n","            state = obs#torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n","            rwd += reward\n","            # done = terminated or truncated\n","            if done:\n","                break\n","    print(rwd)\n","    rwd_list.append(rwd)\n","print(rwd_list, np.mean(rwd_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"id":"a0HLtcF-FNFW","executionInfo":{"status":"error","timestamp":1701295300198,"user_tz":-480,"elapsed":244259,"user":{"displayName":"Adrianus Hans Viary","userId":"12229488510747101526"}},"outputId":"3e4d5a21-85d6-4f25-9e65-0fbcd16b2352"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["Complete\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-7.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["-21.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","\n","    "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-6e4b1e5db975>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m#obs, reward, terminated, truncated , info = env.step(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"zB-QBZ-Z8DV8"},"execution_count":null,"outputs":[]}]}